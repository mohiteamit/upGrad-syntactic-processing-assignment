{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER for Identifying Diseases and Treatments\n",
    "\n",
    "This notebook implements a custom Named Entity Recognition (NER) system to identify diseases and treatments from a medical dataset. The dataset is provided in tokenized format, where each word is associated with a label:\n",
    "- `O` indicates \"Other\"\n",
    "- `D` indicates \"Disease\"\n",
    "- `T` indicates \"Treatment\"\n",
    "\n",
    "## Steps in this Notebook\n",
    "1. **Data Preprocessing:** Reconstruct sentences and labels from the tokenized dataset.\n",
    "2. **Concept Identification:** Identify key concepts in the dataset using PoS tagging.\n",
    "3. **Defining Features for CRF:** Create features for training the CRF model.\n",
    "4. **Getting Features for Words and Sentences:** Apply feature definitions to all sentences.\n",
    "5. **Defining Input and Target Variables:** Prepare input features and labels for training and testing.\n",
    "6. **Building the Model:** Train the CRF model on the training dataset.\n",
    "7. **Evaluating the Model:** Evaluate the model on the test dataset using F1 score and classification metrics.\n",
    "8. **Identifying Diseases and Predicted Treatments:** Extract relationships between diseases and treatments using the trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing\n",
    "The dataset is provided in tokenized format, where each word is stored on a separate line, and sentences are separated by blank lines. In this step, I will:\n",
    "1. Reconstruct sentences and labels from the training and testing datasets.\n",
    "2. Count the number of sentences and labels in the processed datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train dataset: 2599\n",
      "Number of sentences in test dataset: 1056\n",
      "Number of label lines in train dataset: 2599\n",
      "Number of label lines in test dataset: 1056\n"
     ]
    }
   ],
   "source": [
    "# Paths to the dataset files\n",
    "train_sent_path = 'data/train_sent'\n",
    "train_label_path = 'data/train_label'\n",
    "test_sent_path = 'data/test_sent'\n",
    "test_label_path = 'data/test_label'\n",
    "\n",
    "def process_data(file_path):\n",
    "    \"\"\"\n",
    "    Read a dataset file and reconstruct sentences or labels.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the file containing data in tokenized format.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of sentences or labels reconstructed from the file.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # A blank line indicates the end of a sentence\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "            else:\n",
    "                current_sentence.append(line)\n",
    "        if current_sentence:  # Add the last sentence if the file does not end with a blank line\n",
    "            sentences.append(current_sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# Process train and test datasets\n",
    "train_sentences = process_data(train_sent_path)\n",
    "train_labels = process_data(train_label_path)\n",
    "test_sentences = process_data(test_sent_path)\n",
    "test_labels = process_data(test_label_path)\n",
    "\n",
    "# Verify by printing counts\n",
    "print(f\"Number of sentences in train dataset: {len(train_sentences)}\")\n",
    "print(f\"Number of sentences in test dataset: {len(test_sentences)}\")\n",
    "print(f\"Number of label lines in train dataset: {len(train_labels)}\")\n",
    "print(f\"Number of label lines in test dataset: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concept Identification\n",
    "In this step, I will identify key concepts (e.g., diseases and treatments) from the dataset by:\n",
    "1. Performing Part-of-Speech (PoS) tagging on the text data.\n",
    "2. Extracting tokens with PoS tags corresponding to nouns (`NOUN` and `PROPN`).\n",
    "3. Counting the frequency of these tokens across the entire dataset (both training and testing data).\n",
    "4. Printing the top 25 most frequently mentioned concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For formatting outputs\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Concept      |   Frequency |\n",
      "|--------------|-------------|\n",
      "| patients     |         507 |\n",
      "| treatment    |         304 |\n",
      "| %            |         247 |\n",
      "| cancer       |         211 |\n",
      "| therapy      |         177 |\n",
      "| study        |         174 |\n",
      "| disease      |         149 |\n",
      "| cell         |         142 |\n",
      "| lung         |         118 |\n",
      "| results      |         116 |\n",
      "| group        |         111 |\n",
      "| effects      |          99 |\n",
      "| gene         |          91 |\n",
      "| chemotherapy |          91 |\n",
      "| use          |          87 |\n",
      "| effect       |          82 |\n",
      "| women        |          81 |\n",
      "| analysis     |          76 |\n",
      "| risk         |          74 |\n",
      "| surgery      |          73 |\n",
      "| cases        |          72 |\n",
      "| p            |          72 |\n",
      "| rate         |          68 |\n",
      "| survival     |          67 |\n",
      "| response     |          66 |\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy model for PoS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_noun_phrases(sentences):\n",
    "    \"\"\"\n",
    "    Extract nouns and proper nouns from the given sentences.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of tokenized sentences.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of nouns and proper nouns extracted from the sentences.\n",
    "    \"\"\"\n",
    "    nouns = []\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(\" \".join(sentence))\n",
    "        for token in doc:\n",
    "            if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Select nouns and proper nouns\n",
    "                nouns.append(token.text.lower())\n",
    "    return nouns\n",
    "\n",
    "# Combine training and testing sentences for concept identification\n",
    "all_sentences = train_sentences + test_sentences\n",
    "\n",
    "# Extract nouns and calculate their frequencies\n",
    "nouns = extract_noun_phrases(all_sentences)\n",
    "noun_frequencies = Counter(nouns)\n",
    "\n",
    "# Print the top 25 most common nouns\n",
    "table_data = [[concept, freq] for concept, freq in noun_frequencies.most_common(25)]\n",
    "print(tabulate(table_data, headers=[\"Concept\", \"Frequency\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Defining Features for CRF\n",
    "This step involves defining the features for training the Conditional Random Field (CRF) model. The features will capture:\n",
    "1. Word-level attributes (e.g., lowercase form, capitalization, title-case, digits).\n",
    "2. Part-of-Speech (PoS) tags for the current word, as well as preceding and succeeding words.\n",
    "3. Contextual information, such as bigrams and sentence boundaries (start and end indicators).\n",
    "The features are essential for capturing the relationships and contexts necessary for NER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence, i):\n",
    "    \"\"\"\n",
    "    Generate features for a single word in a sentence with context relationships.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list): A list of tokens (words) in the sentence.\n",
    "    i (int): Index of the word in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of features for the word.\n",
    "    \"\"\"\n",
    "    word = sentence[i]\n",
    "    features = {\n",
    "        'word.lower()': word.lower(),  # Lowercase of the word\n",
    "        'word.isupper()': word.isupper(),  # Is the word in uppercase\n",
    "        'word.istitle()': word.istitle(),  # Is the word title-cased\n",
    "        'word.isdigit()': word.isdigit(),  # Is the word a digit\n",
    "    }\n",
    "    \n",
    "    # PoS tagging using spaCy\n",
    "    doc = nlp(\" \".join(sentence))  # Process the sentence using spaCy\n",
    "    pos_tag = doc[i].pos_\n",
    "    features['pos'] = pos_tag  # PoS tag of the current word\n",
    "\n",
    "    # Features for the beginning of a sentence\n",
    "    if i == 0:\n",
    "        features['BOS'] = True  # Beginning of a sentence\n",
    "    else:\n",
    "        features['BOS'] = False  # Not the beginning\n",
    "        features['prev_word.lower()'] = sentence[i-1].lower()  # Lowercase of the previous word\n",
    "        features['prev_word.pos'] = doc[i-1].pos_  # PoS tag of the previous word\n",
    "\n",
    "    # Features for the end of a sentence\n",
    "    if i == len(sentence) - 1:\n",
    "        features['EOS'] = True  # End of a sentence\n",
    "    else:\n",
    "        features['EOS'] = False  # Not the end\n",
    "        features['next_word.lower()'] = sentence[i+1].lower()  # Lowercase of the next word\n",
    "        features['next_word.pos'] = doc[i+1].pos_  # PoS tag of the next word\n",
    "\n",
    "    # Bigram features: Combine current word with previous and next words\n",
    "    if i > 0:\n",
    "        features['bigram.prev'] = sentence[i-1].lower() + \"_\" + word.lower()\n",
    "    if i < len(sentence) - 1:\n",
    "        features['bigram.next'] = word.lower() + \"_\" + sentence[i+1].lower()\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sentence):\n",
    "    \"\"\"\n",
    "    Generate features for all words in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list): A list of tokens (words) in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing features for a word.\n",
    "    \"\"\"\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Getting Features for Words and Sentences\n",
    "Using the feature extraction functions defined earlier, I will generate features for all sentences in the training and testing datasets. This involves:\n",
    "1. Applying `sent2features` to each sentence.\n",
    "2. Preparing the data in a format suitable for training and evaluating the CRF model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_and_labels(sentences, labels):\n",
    "    \"\"\"\n",
    "    Generate features and labels for all sentences in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of sentences, where each sentence is a list of tokens (words).\n",
    "    labels (list): A list of label sequences, where each sequence corresponds to a sentence.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - features (list): A list of feature dictionaries for each sentence.\n",
    "        - labels (list): A list of label sequences for each sentence.\n",
    "    \"\"\"\n",
    "    features = [sent2features(sentence) for sentence in sentences]\n",
    "    return features, labels\n",
    "\n",
    "# Prepare features and labels for the train dataset\n",
    "train_features, train_labels = prepare_features_and_labels(train_sentences, train_labels)\n",
    "\n",
    "# Prepare features and labels for the test dataset\n",
    "test_features, test_labels = prepare_features_and_labels(test_sentences, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Defining Input and Target Variables\n",
    "In this step, I will define the input features and target labels for the CRF model:\n",
    "1. Input Variables: Features extracted for each word in the sentences.\n",
    "2. Target Variables: Corresponding labels (`O`, `D`, `T`) for each word in the sentences.\n",
    "\n",
    "Additionally, I will display a random example from the training dataset in a tabular format to inspect the features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2599\n",
      "Number of testing samples: 1056\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Display the number of samples for training and testing\n",
    "print(f\"Number of training samples: {len(train_features)}\")\n",
    "print(f\"Number of testing samples: {len(test_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Example from Training Set (Index 1892):\n",
      "|   Index | Word           | Label   | Feature 1                    | Feature 2             | Feature 3             | Feature 4             | Feature 5   | Feature 6   | Feature 7                         | Feature 8             | Feature 9          | Feature 10                     |\n",
      "|---------|----------------|---------|------------------------------|-----------------------|-----------------------|-----------------------|-------------|-------------|-----------------------------------|-----------------------|--------------------|--------------------------------|\n",
      "|       1 | Immunogenicity | O       | word.lower(): immunogenicity | word.isupper(): False | word.istitle(): True  | word.isdigit(): False | pos: NOUN   | BOS: True   | EOS: False                        | next_word.lower(): of | next_word.pos: ADP | bigram.next: immunogenicity_of |\n",
      "|       2 | of             | O       | word.lower(): of             | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: ADP    | BOS: False  | prev_word.lower(): immunogenicity | prev_word.pos: NOUN   | EOS: False         | next_word.lower(): hepatitis   |\n",
      "|       3 | hepatitis      | D       | word.lower(): hepatitis      | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: PROPN  | BOS: False  | prev_word.lower(): of             | prev_word.pos: ADP    | EOS: False         | next_word.lower(): b           |\n",
      "|       4 | B              | D       | word.lower(): b              | word.isupper(): True  | word.istitle(): True  | word.isdigit(): False | pos: PROPN  | BOS: False  | prev_word.lower(): hepatitis      | prev_word.pos: PROPN  | EOS: False         | next_word.lower(): vaccine     |\n",
      "|       5 | vaccine        | T       | word.lower(): vaccine        | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: NOUN   | BOS: False  | prev_word.lower(): b              | prev_word.pos: PROPN  | EOS: False         | next_word.lower(): in          |\n",
      "|       6 | in             | O       | word.lower(): in             | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: ADP    | BOS: False  | prev_word.lower(): vaccine        | prev_word.pos: NOUN   | EOS: False         | next_word.lower(): term        |\n",
      "|       7 | term           | O       | word.lower(): term           | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: NOUN   | BOS: False  | prev_word.lower(): in             | prev_word.pos: ADP    | EOS: False         | next_word.lower(): and         |\n",
      "|       8 | and            | O       | word.lower(): and            | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: CCONJ  | BOS: False  | prev_word.lower(): term           | prev_word.pos: NOUN   | EOS: False         | next_word.lower(): preterm     |\n",
      "|       9 | preterm        | O       | word.lower(): preterm        | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: NOUN   | BOS: False  | prev_word.lower(): and            | prev_word.pos: CCONJ  | EOS: False         | next_word.lower(): infants     |\n",
      "|      10 | infants        | O       | word.lower(): infants        | word.isupper(): False | word.istitle(): False | word.isdigit(): False | pos: NOUN   | BOS: False  | prev_word.lower(): preterm        | prev_word.pos: NOUN   | EOS: True          | bigram.prev: preterm_infants   |\n"
     ]
    }
   ],
   "source": [
    "# Function to display features and labels in a tabular format\n",
    "def display_random_example(features, labels, sentences):\n",
    "    \"\"\"\n",
    "    Display a random example from the dataset in a tabular format.\n",
    "\n",
    "    Parameters:\n",
    "    features (list): List of feature dictionaries for the dataset.\n",
    "    labels (list): List of label sequences corresponding to the features.\n",
    "    sentences (list): List of tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Select a random example\n",
    "    random_index = random.randint(0, len(features) - 1)\n",
    "    example_features = features[random_index]\n",
    "    example_labels = labels[random_index]\n",
    "    example_sentence = sentences[random_index]\n",
    "    \n",
    "    # Prepare the data for tabulation\n",
    "    table_data = []\n",
    "    for i, (word, label, feature) in enumerate(zip(example_sentence, example_labels, example_features)):\n",
    "        row = [i + 1, word, label] + [f\"{key}: {value}\" for key, value in feature.items()]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Define headers for the table\n",
    "    headers = [\"Index\", \"Word\", \"Label\"] + [f\"Feature {i + 1}\" for i in range(len(example_features[0]))]\n",
    "    \n",
    "    # Display the table using tabulate\n",
    "    print(f\"\\nRandom Example from Training Set (Index {random_index}):\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"github\"))\n",
    "\n",
    "# Display a random example from the training set\n",
    "display_random_example(train_features, train_labels, train_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Building the Model\n",
    "\n",
    "In this step, I will build and train a Conditional Random Field (CRF) model for the custom NER task. The CRF model learns relationships between words, their features, and corresponding labels (`O`, `D`, `T`). The model will be trained using the features and labels prepared in the previous steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CRF<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# Initialize the CRF model\n",
    "crf_model = CRF(\n",
    "    algorithm='lbfgs',  # Optimization algorithm\n",
    "    c1=0.1,             # Coefficient for L1 regularization\n",
    "    c2=0.1,             # Coefficient for L2 regularization\n",
    "    max_iterations=100, # Maximum number of iterations\n",
    "    all_possible_transitions=True  # Allow transitions between all states\n",
    ")\n",
    "\n",
    "# Train the CRF model on the training data\n",
    "crf_model.fit(train_features, train_labels)\n",
    "\n",
    "crf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluating the Model\n",
    "In this step, I will evaluate the CRF model's performance using the test dataset. The model will:\n",
    "1. Predict labels for each token in the test sentences.\n",
    "2. Calculate the F1 score for overall performance.\n",
    "3. Display a detailed classification report to analyze the model's predictions for each label (`O`, `D`, `T`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.91\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O      0.931     0.983     0.956     16127\n",
      "           D      0.828     0.560     0.668      1450\n",
      "           T      0.813     0.468     0.594      1041\n",
      "\n",
      "    accuracy                          0.922     18618\n",
      "   macro avg      0.857     0.670     0.739     18618\n",
      "weighted avg      0.916     0.922     0.914     18618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# Predict labels for the test dataset\n",
    "test_predictions = crf_model.predict(test_features)\n",
    "\n",
    "# Evaluate the model using the F1 score\n",
    "f1_score = metrics.flat_f1_score(\n",
    "    test_labels, test_predictions, average='weighted', labels=crf_model.classes_\n",
    ")\n",
    "\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Print classification report for detailed evaluation\n",
    "classification_report = metrics.flat_classification_report(\n",
    "    test_labels, test_predictions, labels=crf_model.classes_, digits=3\n",
    ")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Identifying Diseases and Predicted Treatments\n",
    "In this step, I will extract diseases and their corresponding treatments from the test dataset using the trained CRF model. The output will be structured as a dictionary, where:\n",
    "- Each disease (label `D`) is a key.\n",
    "- Treatments (label `T`) associated with the disease are the values.\n",
    "Additionally, the results for the specific disease \"hereditary retinoblastoma\" will be explicitly extracted to meet the assignment's requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load spaCy's small English model for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_diseases_and_treatments(sentences, predictions):\n",
    "    \"\"\"\n",
    "    Extract diseases and treatments, including descriptive multi-word entities,\n",
    "    with reduced noise using dependency parsing and validation.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of tokenized sentences.\n",
    "    predictions (list): A list of predicted label sequences for each sentence.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are diseases (D) with descriptors and values are lists of treatments (T).\n",
    "    \"\"\"\n",
    "    disease_treatment_map = defaultdict(list)\n",
    "\n",
    "    def is_valid_entity(entity):\n",
    "        \"\"\"\n",
    "        Validate if the extracted entity is meaningful.\n",
    "\n",
    "        Parameters:\n",
    "        entity (str): The entity to validate.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if the entity is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        # Disallow entities with invalid characters or overly short entities\n",
    "        if re.search(r\"[()\\d]\", entity) or len(entity.split()) < 1:\n",
    "            return False\n",
    "        # Exclude overly generic terms\n",
    "        if entity.lower() in [\"disease\", \"cancer\", \"advanced disease\"]:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_valid_treatment(treatment):\n",
    "        \"\"\"\n",
    "        Validate if the extracted treatment is meaningful.\n",
    "\n",
    "        Parameters:\n",
    "        treatment (str): The treatment to validate.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if the treatment is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        # Exclude generic terms and overly short treatments\n",
    "        invalid_terms = {\"and\", \"with\", \"the\", \"of\"}\n",
    "        return treatment.isalpha() and len(treatment) > 2 and treatment.lower() not in invalid_terms\n",
    "\n",
    "    for sentence, prediction in zip(sentences, predictions):\n",
    "        # Convert the tokenized sentence into a spaCy Doc object for dependency parsing\n",
    "        doc = nlp(\" \".join(sentence))\n",
    "\n",
    "        current_disease = None\n",
    "        for idx, (word, label) in enumerate(zip(sentence, prediction)):\n",
    "            if label == \"D\":  # Identify disease\n",
    "                # Start forming a multi-word entity\n",
    "                token = doc[idx]\n",
    "                descriptor = set()\n",
    "\n",
    "                # Add adjectives or compound descriptors linked to the disease\n",
    "                for child in token.children:\n",
    "                    if child.dep_ in [\"amod\", \"compound\"] and child.pos_ in [\"ADJ\", \"NOUN\"]:\n",
    "                        descriptor.add(child.text)\n",
    "\n",
    "                # Check for preceding descriptors in the sentence\n",
    "                j = idx - 1\n",
    "                while j >= 0 and prediction[j] == \"O\":\n",
    "                    prev_token = doc[j]\n",
    "                    if prev_token.dep_ in [\"amod\", \"compound\"] and prev_token.pos_ in [\"ADJ\", \"NOUN\"]:\n",
    "                        descriptor.add(sentence[j])\n",
    "                    j -= 1\n",
    "\n",
    "                # Combine descriptor with the disease\n",
    "                descriptor_list = list(descriptor)\n",
    "                current_disease = \" \".join(descriptor_list + [word])\n",
    "\n",
    "                # Include subsequent words labeled as `D` to form a multi-word entity\n",
    "                k = idx + 1\n",
    "                while k < len(sentence) and prediction[k] == \"D\":\n",
    "                    current_disease += f\" {sentence[k]}\"\n",
    "                    k += 1\n",
    "\n",
    "                # Skip to the last word of the entity\n",
    "                idx = k - 1\n",
    "\n",
    "                # Validate disease entity\n",
    "                if not is_valid_entity(current_disease):\n",
    "                    current_disease = None\n",
    "\n",
    "            elif label == \"T\" and current_disease:  # Associate treatment with the disease\n",
    "                if is_valid_treatment(word):\n",
    "                    disease_treatment_map[current_disease].append(word)\n",
    "\n",
    "    # Post-process the map to remove non-alphabetic treatments and normalize phrases\n",
    "    final_map = {}\n",
    "    for disease, treatments in disease_treatment_map.items():\n",
    "        meaningful_treatments = list(set(t for t in treatments if is_valid_treatment(t)))  # Deduplicate treatments\n",
    "        if is_valid_entity(disease):\n",
    "            final_map[disease] = meaningful_treatments\n",
    "\n",
    "    return final_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract diseases and treatments using test sentences and predictions\n",
    "disease_treatment_dict = extract_diseases_and_treatments(test_sentences, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Disease-Treatment Dictionary:\n",
      "| Disease                                   | Treatments                                                              |\n",
      "|-------------------------------------------|-------------------------------------------------------------------------|\n",
      "| diabetes gestational cases                | control, good, glycemic                                                 |\n",
      "| hereditary retinoblastoma                 | radiotherapy                                                            |\n",
      "| myocardial infarction                     | aspirin, warfarin                                                       |\n",
      "| hemorrhagic stroke                        | alteplase, infusion, accelerated                                        |\n",
      "| proteinuric hypertension                  | insemination, donor, intrauterine, sperm                                |\n",
      "| insemination partner preeclampsia         | insemination, donor                                                     |\n",
      "| mesothelioma                              | radiotherapy, chemotherapy                                              |\n",
      "| testicular bleeding                       | needle, fine, aspiration                                                |\n",
      "| pulmonary primary hypertension            | fenfluramine                                                            |\n",
      "| nsclc                                     | treatment, surgical                                                     |\n",
      "| concurrent acute rejection                | extracorporeal, therapy, photopheresis                                  |\n",
      "| lung carcinoma                            | videothoracoscopic, partial, lung, lobectomy, resection                 |\n",
      "| metastasis                                | surgical, resection                                                     |\n",
      "| consecutive brain advanced clinical nsclc | cisplatin, irinotecan, chemotherapy, combination, ifosfamide, support   |\n",
      "| metastatic colorectal cancer              | other, agents                                                           |\n",
      "| primary tumor                             | resection                                                               |\n",
      "| lung primary cancer                       | resection                                                               |\n",
      "| symptomatic metastases                    | radiotherapy                                                            |\n",
      "| primary cancer                            | therapy, adjuvant, radiation                                            |\n",
      "| year overall complete response among sclc | carboplatin, combination, therapy                                       |\n",
      "| neck cancer                               | amifostine, therapy, irradiation, intravenous                           |\n",
      "| Successful psoriasis                      | analogue, active, vitamin                                               |\n",
      "| melanoma                                  | interferon, recombinant                                                 |\n",
      "| metastases                                | lanreotide, therapy                                                     |\n",
      "| infection                                 | combination, clarithromycin, omeprazole, amoxicillin                    |\n",
      "| viremia                                   | combination, therapy                                                    |\n",
      "| severe hypoxemia                          | glucocorticoid, therapy, pulse                                          |\n",
      "| malignant melanoma                        | interferon                                                              |\n",
      "| esophageal achalasia                      | injection, pneumatic, laparoscopic, dilation, myotomy, botulinum, toxin |\n",
      "| cell sickle disease                       | hydroxyurea                                                             |\n",
      "| hepatitis B                               | vaccine                                                                 |\n"
     ]
    }
   ],
   "source": [
    "# Display the complete disease-treatment mapping\n",
    "print(\"\\nComplete Disease-Treatment Dictionary:\")\n",
    "table_data = [[disease, ', '.join(treatments)] for disease, treatments in disease_treatment_dict.items()]\n",
    "print(tabulate(table_data, headers=[\"Disease\", \"Treatments\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted treatments for the disease 'hereditary retinoblastoma': radiotherapy\n"
     ]
    }
   ],
   "source": [
    "# Display results for \"hereditary retinoblastoma\"\n",
    "specific_disease = \"hereditary retinoblastoma\"\n",
    "specific_treatments = disease_treatment_dict.get(specific_disease, [])\n",
    "\n",
    "if specific_treatments:\n",
    "    print(f\"Predicted treatments for the disease '{specific_disease}': {', '.join(specific_treatments)}\")\n",
    "else:\n",
    "    print(f\"No treatments found for the disease '{specific_disease}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
