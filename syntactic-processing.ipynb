{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER for Identifying Diseases and Treatments\n",
    "\n",
    "This notebook implements a custom Named Entity Recognition (NER) system to identify diseases and treatments from a medical dataset. The dataset is provided in tokenized format, where each word is associated with a label:\n",
    "- `O` indicates \"Other\"\n",
    "- `D` indicates \"Disease\"\n",
    "- `T` indicates \"Treatment\"\n",
    "\n",
    "## Steps in this Notebook\n",
    "1. **Data Preprocessing:** Reconstruct sentences and labels from the tokenized dataset.\n",
    "2. **Concept Identification:** Identify key concepts in the dataset using PoS tagging.\n",
    "3. **Defining Features for CRF:** Create features for training the CRF model.\n",
    "4. **Getting Features for Words and Sentences:** Apply feature definitions to all sentences.\n",
    "5. **Defining Input and Target Variables:** Prepare input features and labels for training and testing.\n",
    "6. **Building the Model:** Train the CRF model on the training dataset.\n",
    "7. **Evaluating the Model:** Evaluate the model on the test dataset using F1 score and classification metrics.\n",
    "8. **Identifying Diseases and Predicted Treatments:** Extract relationships between diseases and treatments using the trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing\n",
    "The dataset is provided in tokenized format, where each word is stored on a separate line, and sentences are separated by blank lines. In this step, I will:\n",
    "1. Reconstruct sentences and labels from the training and testing datasets.\n",
    "2. Count the number of sentences and labels in the processed datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the dataset files\n",
    "train_sent_path = 'data/train_sent'\n",
    "train_label_path = 'data/train_label'\n",
    "test_sent_path = 'data/test_sent'\n",
    "test_label_path = 'data/test_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_no_entity_statements(sentences, labels):\n",
    "    \"\"\"\n",
    "    Filters out sentences and their corresponding labels that do not contain any entity labels ('D' or 'T').\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of tokenized sentences, where each sentence is a list of words.\n",
    "    labels (list): A list of label sequences, where each sequence corresponds to a sentence.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Filtered lists of sentences and labels.\n",
    "    \"\"\"\n",
    "    filtered_sentences = []\n",
    "    filtered_labels = []\n",
    "\n",
    "    for sentence, label_sequence in zip(sentences, labels):\n",
    "        # Check if the label sequence contains any 'D' or 'T' labels\n",
    "        if any(label in {'D', 'T'} for label in label_sequence):\n",
    "            filtered_sentences.append(sentence)\n",
    "            filtered_labels.append(label_sequence)\n",
    "\n",
    "    return filtered_sentences, filtered_labels\n",
    "\n",
    "def clean_sentence(sentence, labels):\n",
    "    \"\"\"\n",
    "    Cleans a tokenized sentence by normalizing, removing noise, and correcting token splits.\n",
    "    Adjusts the labels accordingly to ensure alignment with cleaned tokens.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list): A list of tokens (words) in the sentence.\n",
    "    labels (list): A list of labels corresponding to the tokens.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A cleaned list of tokens and their adjusted labels.\n",
    "    \"\"\"\n",
    "    cleaned_sentence = []\n",
    "    cleaned_labels = []\n",
    "\n",
    "    for token, label in zip(sentence, labels):\n",
    "        # Remove special characters except hyphens in compound words\n",
    "        cleaned_token = re.sub(r'[^\\w\\-]', '', token)\n",
    "\n",
    "        # Preserve meaningful hyphenated words, otherwise split on hyphen\n",
    "        if '-' in cleaned_token and len(cleaned_token.split('-')) > 1:\n",
    "            sub_tokens = cleaned_token.split('-')\n",
    "            if all(len(sub) > 1 for sub in sub_tokens):  # If all parts are meaningful\n",
    "                cleaned_sentence.append(cleaned_token)\n",
    "                cleaned_labels.append(label)\n",
    "            else:\n",
    "                for sub_token in sub_tokens:\n",
    "                    cleaned_sentence.append(sub_token)\n",
    "                    cleaned_labels.append(label)\n",
    "        else:\n",
    "            # Lowercase all tokens except acronyms or proper nouns\n",
    "            if cleaned_token.isupper() and len(cleaned_token) > 1:  # Acronyms like \"HIV\"\n",
    "                cleaned_sentence.append(cleaned_token)\n",
    "                cleaned_labels.append(label)\n",
    "            else:\n",
    "                cleaned_sentence.append(cleaned_token.lower())\n",
    "                cleaned_labels.append(label)\n",
    "\n",
    "    # Filter out empty tokens or noise tokens\n",
    "    final_sentence = []\n",
    "    final_labels = []\n",
    "    for tok, lab in zip(cleaned_sentence, cleaned_labels):\n",
    "        if tok and re.search(r'[a-zA-Z]', tok):  # Ensure valid tokens remain\n",
    "            final_sentence.append(tok)\n",
    "            final_labels.append(lab)\n",
    "\n",
    "    return final_sentence, final_labels\n",
    "\n",
    "\n",
    "def clean_dataset(sentences, labels):\n",
    "    \"\"\"\n",
    "    Cleans a dataset of tokenized sentences and adjusts their corresponding labels.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of sentences, where each sentence is a list of tokens.\n",
    "    labels (list): A list of label sequences, where each sequence corresponds to a sentence.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A cleaned list of sentences and their adjusted labels.\n",
    "    \"\"\"\n",
    "    cleaned_sentences = []\n",
    "    cleaned_labels = []\n",
    "\n",
    "    for sentence, label_sequence in zip(sentences, labels):\n",
    "        cleaned_sentence, cleaned_label = clean_sentence(sentence, label_sequence)\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "        cleaned_labels.append(cleaned_label)\n",
    "\n",
    "    return cleaned_sentences, cleaned_labels\n",
    "\n",
    "def process_data(file_path):\n",
    "    \"\"\"\n",
    "    Read a dataset file and reconstruct sentences or labels.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the file containing data in tokenized format.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of sentences or labels reconstructed from the file.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # A blank line indicates the end of a sentence\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "            else:\n",
    "                current_sentence.append(line)\n",
    "        if current_sentence:  # Add the last sentence if the file does not end with a blank line\n",
    "            sentences.append(current_sentence)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train dataset: 2599\n",
      "Number of label lines in train dataset: 2599\n",
      "Number of sentences in test dataset: 1056\n",
      "Number of label lines in test dataset: 1056\n"
     ]
    }
   ],
   "source": [
    "# Process train and test datasets\n",
    "train_sentences = process_data(train_sent_path)\n",
    "train_labels = process_data(train_label_path)\n",
    "test_sentences = process_data(test_sent_path)\n",
    "test_labels = process_data(test_label_path)\n",
    "\n",
    "# Verify by printing counts\n",
    "print(f\"Number of sentences in train dataset: {len(train_sentences)}\")\n",
    "print(f\"Number of label lines in train dataset: {len(train_labels)}\")\n",
    "print(f\"Number of sentences in test dataset: {len(test_sentences)}\")\n",
    "print(f\"Number of label lines in test dataset: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data upfront for noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train dataset: 2599\n",
      "Number of label lines in train dataset: 2599\n",
      "Number of sentences in test dataset: 1056\n",
      "Number of label lines in test dataset: 1056\n"
     ]
    }
   ],
   "source": [
    "# train_sentences, train_labels = clean_dataset(train_sentences, train_labels)\n",
    "# test_sentences, test_labels = clean_dataset(test_sentences, test_labels)\n",
    "\n",
    "# train_sentences, train_labels = filter_no_entity_statements(sentences=train_sentences, labels=train_labels)\n",
    "# test_sentences, test_labels = filter_no_entity_statements(sentences=test_sentences, labels=test_labels)\n",
    "\n",
    "# Verify by printing counts\n",
    "print(f\"Number of sentences in train dataset: {len(train_sentences)}\")\n",
    "print(f\"Number of label lines in train dataset: {len(train_labels)}\")\n",
    "\n",
    "print(f\"Number of sentences in test dataset: {len(test_sentences)}\")\n",
    "print(f\"Number of label lines in test dataset: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : I concluded on not cleaning any data upfront as all attempts were detremental to model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concept Identification\n",
    "In this step, I will identify key concepts (e.g., diseases and treatments) from the dataset by:\n",
    "1. Performing Part-of-Speech (PoS) tagging on the text data.\n",
    "2. Extracting tokens with PoS tags corresponding to nouns (`NOUN` and `PROPN`).\n",
    "3. Counting the frequency of these tokens across the entire dataset (both training and testing data).\n",
    "4. Printing the top 25 most frequently mentioned concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For formatting outputs\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "try:\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    download(\"en_core_web_sm\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy model for PoS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_noun_phrases(sentences):\n",
    "    \"\"\"\n",
    "    Extract nouns and proper nouns from the given sentences.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of tokenized sentences.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of nouns and proper nouns extracted from the sentences.\n",
    "    \"\"\"\n",
    "    nouns = []\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(\" \".join(sentence))\n",
    "        for token in doc:\n",
    "            if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Select nouns and proper nouns\n",
    "                nouns.append(token.text.lower())\n",
    "    return nouns\n",
    "\n",
    "# Combine training and testing sentences for concept identification\n",
    "all_sentences = train_sentences + test_sentences\n",
    "\n",
    "# Extract nouns and calculate their frequencies\n",
    "nouns = extract_noun_phrases(all_sentences)\n",
    "noun_frequencies = Counter(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   # | Concept      |   Frequency |\n",
      "|-----|--------------|-------------|\n",
      "|   1 | patients     |         507 |\n",
      "|   2 | treatment    |         304 |\n",
      "|   3 | %            |         247 |\n",
      "|   4 | cancer       |         211 |\n",
      "|   5 | therapy      |         177 |\n",
      "|   6 | study        |         174 |\n",
      "|   7 | disease      |         149 |\n",
      "|   8 | cell         |         142 |\n",
      "|   9 | lung         |         118 |\n",
      "|  10 | results      |         116 |\n",
      "|  11 | group        |         111 |\n",
      "|  12 | effects      |          99 |\n",
      "|  13 | gene         |          91 |\n",
      "|  14 | chemotherapy |          91 |\n",
      "|  15 | use          |          87 |\n",
      "|  16 | effect       |          82 |\n",
      "|  17 | women        |          81 |\n",
      "|  18 | analysis     |          76 |\n",
      "|  19 | risk         |          74 |\n",
      "|  20 | surgery      |          73 |\n",
      "|  21 | cases        |          72 |\n",
      "|  22 | p            |          72 |\n",
      "|  23 | rate         |          68 |\n",
      "|  24 | survival     |          67 |\n",
      "|  25 | response     |          66 |\n"
     ]
    }
   ],
   "source": [
    "# Print the top 25 most common nouns\n",
    "table_data = [[i, concept, freq] for i, (concept, freq) in enumerate(noun_frequencies.most_common(25), start=1)]\n",
    "print(tabulate(table_data, headers=['#', \"Concept\", \"Frequency\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   # | Concept           |   Frequency |\n",
      "|-----|-------------------|-------------|\n",
      "|   1 | abortion          |           1 |\n",
      "|   2 | myeloma           |           1 |\n",
      "|   3 | tandem            |           1 |\n",
      "|   4 | occlusions        |           1 |\n",
      "|   5 | thrombogenicity   |           1 |\n",
      "|   6 | vasoreactivity    |           1 |\n",
      "|   7 | epoetin           |           1 |\n",
      "|   8 | timolol           |           1 |\n",
      "|   9 | tartrate          |           1 |\n",
      "|  10 | brimonidine       |           1 |\n",
      "|  11 | poliovirus        |           1 |\n",
      "|  12 | poliomyelitis     |           1 |\n",
      "|  13 | celecoxib         |           1 |\n",
      "|  14 | formoterol        |           1 |\n",
      "|  15 | dry               |           1 |\n",
      "|  16 | levodopa          |           1 |\n",
      "|  17 | methyltransferase |           1 |\n",
      "|  18 | catechol          |           1 |\n",
      "|  19 | tolcapone         |           1 |\n",
      "|  20 | colonoscopy       |           1 |\n",
      "|  21 | malathion         |           1 |\n",
      "|  22 | spoon             |           1 |\n",
      "|  23 | thera             |           1 |\n",
      "|  24 | ascorbic          |           1 |\n",
      "|  25 | bisoprolol        |           1 |\n"
     ]
    }
   ],
   "source": [
    "# Print the top 25 least common nouns\n",
    "table_data = [[i, concept, freq] for i, (concept, freq) in enumerate(noun_frequencies.most_common()[:-26:-1], start=1)]\n",
    "print(tabulate(table_data, headers=['#', \"Concept\", \"Frequency\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Defining Features for CRF\n",
    "This step involves defining the features for training the Conditional Random Field (CRF) model. The features will capture:\n",
    "1. Word-level attributes (e.g., lowercase form, capitalization, title-case, digits).\n",
    "2. Part-of-Speech (PoS) tags for the current word, as well as preceding and succeeding words.\n",
    "3. Contextual information, such as bigrams and sentence boundaries (start and end indicators).\n",
    "The features are essential for capturing the relationships and contexts necessary for NER.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Feature Selection\n",
    "\n",
    "1. **Word-Level Features**: Capture basic properties of words, such as case, prefixes, suffixes, and the presence of hyphens, to recognize patterns in medical terms.\n",
    "2. **POS and Dependency Features**: Utilize spaCy's Part-of-Speech tagging and dependency parsing to capture syntactic roles and relationships in the sentence.\n",
    "3. **Contextual Features**: Include the previous and next words and their grammatical roles to provide a broader context for each word.\n",
    "4. **N-grams**: Create bigram features to identify relationships between consecutive words, such as compound terms or descriptors.\n",
    "5. **Phrase Boundary Features**: Detect modifiers (e.g., adjectives or compounds) that indicate the start or end of an entity phrase.\n",
    "6. **Sentence Position**: Use markers for the beginning and end of sentences to help identify potential boundaries of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence, i):\n",
    "    \"\"\"\n",
    "    Generate features for a single word in a sentence with context relationships.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list): A list of tokens (words) in the sentence.\n",
    "    i (int): Index of the word in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of features for the word.\n",
    "    \"\"\"\n",
    "    word = sentence[i]\n",
    "    features = {\n",
    "        'word.lower()': word.lower(),  # Lowercased word\n",
    "        'word.prefix': word[:3].lower(),  # First 3 characters\n",
    "        'word.suffix': word[-3:].lower(),  # Last 3 characters\n",
    "    }\n",
    "\n",
    "    # PoS tagging using spaCy\n",
    "    doc = nlp(\" \".join(sentence))\n",
    "    token = doc[i]\n",
    "    features['pos'] = token.pos_\n",
    "    features['dep'] = token.dep_\n",
    "    features['head'] = token.head.text.lower()  # Head word\n",
    "    features['head.pos'] = token.head.pos_\n",
    "\n",
    "    # Features for the beginning and end of a sentence\n",
    "    features['BOS'] = (i == 0)  # Beginning of the sentence\n",
    "    features['EOS'] = (i == len(sentence) - 1)  # End of the sentence\n",
    "\n",
    "    # Features for previous word\n",
    "    if i > 0:\n",
    "        prev_token = doc[i - 1]\n",
    "        features.update({\n",
    "            'prev_word.lower()': sentence[i - 1].lower(),\n",
    "            'prev_word.pos': prev_token.pos_,\n",
    "            'prev_word.dep': prev_token.dep_,\n",
    "        })\n",
    "    else:\n",
    "        features['prev_word.lower()'] = '<START>'\n",
    "\n",
    "    # Features for next word\n",
    "    if i < len(sentence) - 1:\n",
    "        next_token = doc[i + 1]\n",
    "        features.update({\n",
    "            'next_word.lower()': sentence[i + 1].lower(),\n",
    "            'next_word.pos': next_token.pos_,\n",
    "            'next_word.dep': next_token.dep_,\n",
    "        })\n",
    "    else:\n",
    "        features['next_word.lower()'] = '<END>'\n",
    "\n",
    "    # N-gram features\n",
    "    if i > 0:\n",
    "        features['bigram.prev'] = sentence[i - 1].lower() + '_' + word.lower()\n",
    "    if i < len(sentence) - 1:\n",
    "        features['bigram.next'] = word.lower() + '_' + sentence[i + 1].lower()\n",
    "    if i > 1:\n",
    "        features['trigram.prev'] = sentence[i - 2].lower() + '_' + sentence[i - 1].lower() + '_' + word.lower()\n",
    "    if i < len(sentence) - 2:\n",
    "        features['trigram.next'] = word.lower() + '_' + sentence[i + 1].lower() + '_' + sentence[i + 2].lower()\n",
    "\n",
    "    # Phrase boundary features\n",
    "    features['is_descriptor'] = token.dep_ in ['amod', 'compound']\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sentence):\n",
    "    \"\"\"\n",
    "    Generate features for all words in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (list): A list of tokens (words) in the sentence.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing features for a word.\n",
    "    \"\"\"\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Getting Features for Words and Sentences\n",
    "Using the feature extraction functions defined earlier, I will generate features for all sentences in the training and testing datasets. This involves:\n",
    "1. Applying `sent2features` to each sentence.\n",
    "2. Preparing the data in a format suitable for training and evaluating the CRF model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - run feature extraction in parallel to speed up\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def prepare_features_and_labels(sentences, labels):\n",
    "#     \"\"\"\n",
    "#     Generate features and labels for all sentences in the dataset.\n",
    "\n",
    "#     Parameters:\n",
    "#     sentences (list): A list of sentences, where each sentence is a list of tokens (words).\n",
    "#     labels (list): A list of label sequences, where each sequence corresponds to a sentence.\n",
    "\n",
    "#     Returns:\n",
    "#     tuple: A tuple containing:\n",
    "#         - features (list): A list of feature dictionaries for each sentence.\n",
    "#         - labels (list): A list of label sequences for each sentence.\n",
    "#     \"\"\"\n",
    "#     # Parallelize the sentence feature extraction using threads\n",
    "#     features = Parallel(n_jobs=-1, prefer=\"threads\")(delayed(sent2features)(sentence) for sentence in sentences)\n",
    "#     return features, labels\n",
    "\n",
    "# # Prepare features and labels for the train dataset\n",
    "# train_features, train_labels = prepare_features_and_labels(train_sentences, train_labels)\n",
    "\n",
    "# # Prepare features and labels for the test dataset\n",
    "# test_features, test_labels = prepare_features_and_labels(test_sentences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_and_labels(sentences, labels):\n",
    "    \"\"\"\n",
    "    Generate features and labels for all sentences in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of sentences, where each sentence is a list of tokens (words).\n",
    "    labels (list): A list of label sequences, where each sequence corresponds to a sentence.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - features (list): A list of feature dictionaries for each sentence.\n",
    "        - labels (list): A list of label sequences for each sentence.\n",
    "    \"\"\"\n",
    "    features = [sent2features(sentence) for sentence in sentences]\n",
    "    return features, labels\n",
    "\n",
    "# Prepare features and labels for the train dataset\n",
    "train_features, train_labels = prepare_features_and_labels(train_sentences, train_labels)\n",
    "\n",
    "# Prepare features and labels for the test dataset\n",
    "test_features, test_labels = prepare_features_and_labels(test_sentences, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Defining Input and Target Variables\n",
    "In this step, I will define the input features and target labels for the CRF model:\n",
    "1. Input Variables: Features extracted for each word in the sentences.\n",
    "2. Target Variables: Corresponding labels (`O`, `D`, `T`) for each word in the sentences.\n",
    "\n",
    "Additionally, I will display a random example from the training dataset in a tabular format to inspect the features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2599\n",
      "Number of testing samples: 1056\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Display the number of samples for training and testing\n",
    "print(f\"Number of training samples: {len(train_features)}\")\n",
    "print(f\"Number of testing samples: {len(test_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Example from Training Set (Index 2412):\n",
      "|   Index | Word         | Label   | Feature 1                  | Feature 2        | Feature 3        | Feature 4   | Feature 5     | Feature 6         | Feature 7      | Feature 8   | Feature 9   | Feature 10                      | Feature 11                      | Feature 12              | Feature 13                      | Feature 14                       | Feature 15                                     | Feature 16                             |\n",
      "|---------|--------------|---------|----------------------------|------------------|------------------|-------------|---------------|-------------------|----------------|-------------|-------------|---------------------------------|---------------------------------|-------------------------|---------------------------------|----------------------------------|------------------------------------------------|----------------------------------------|\n",
      "|       1 | Direct       | T       | word.lower(): direct       | word.prefix: dir | word.suffix: ect | pos: ADJ    | dep: amod     | head: angioplasty | head.pos: NOUN | BOS: True   | EOS: False  | prev_word.lower(): <START>      | next_word.lower(): percutaneous | next_word.pos: ADJ      | next_word.dep: amod             | bigram.next: direct_percutaneous | trigram.next: direct_percutaneous_transluminal | is_descriptor: True                    |\n",
      "|       2 | percutaneous | T       | word.lower(): percutaneous | word.prefix: per | word.suffix: ous | pos: ADJ    | dep: amod     | head: angioplasty | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): direct       | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): transluminal | next_word.pos: ADJ               | next_word.dep: amod                            | bigram.prev: direct_percutaneous       |\n",
      "|       3 | transluminal | T       | word.lower(): transluminal | word.prefix: tra | word.suffix: nal | pos: ADJ    | dep: amod     | head: angioplasty | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): percutaneous | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): angioplasty  | next_word.pos: NOUN              | next_word.dep: ROOT                            | bigram.prev: percutaneous_transluminal |\n",
      "|       4 | angioplasty  | T       | word.lower(): angioplasty  | word.prefix: ang | word.suffix: sty | pos: NOUN   | dep: ROOT     | head: angioplasty | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): transluminal | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): for          | next_word.pos: ADP               | next_word.dep: prep                            | bigram.prev: transluminal_angioplasty  |\n",
      "|       5 | for          | O       | word.lower(): for          | word.prefix: for | word.suffix: for | pos: ADP    | dep: prep     | head: angioplasty | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): angioplasty  | prev_word.pos: NOUN             | prev_word.dep: ROOT     | next_word.lower(): acute        | next_word.pos: ADJ               | next_word.dep: amod                            | bigram.prev: angioplasty_for           |\n",
      "|       6 | acute        | D       | word.lower(): acute        | word.prefix: acu | word.suffix: ute | pos: ADJ    | dep: amod     | head: occlusion   | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): for          | prev_word.pos: ADP              | prev_word.dep: prep     | next_word.lower(): middle       | next_word.pos: ADJ               | next_word.dep: amod                            | bigram.prev: for_acute                 |\n",
      "|       7 | middle       | D       | word.lower(): middle       | word.prefix: mid | word.suffix: dle | pos: ADJ    | dep: amod     | head: cerebral    | head.pos: ADJ  | BOS: False  | EOS: False  | prev_word.lower(): acute        | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): cerebral     | next_word.pos: ADJ               | next_word.dep: amod                            | bigram.prev: acute_middle              |\n",
      "|       8 | cerebral     | D       | word.lower(): cerebral     | word.prefix: cer | word.suffix: ral | pos: ADJ    | dep: amod     | head: occlusion   | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): middle       | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): artery       | next_word.pos: NOUN              | next_word.dep: compound                        | bigram.prev: middle_cerebral           |\n",
      "|       9 | artery       | D       | word.lower(): artery       | word.prefix: art | word.suffix: ery | pos: NOUN   | dep: compound | head: occlusion   | head.pos: NOUN | BOS: False  | EOS: False  | prev_word.lower(): cerebral     | prev_word.pos: ADJ              | prev_word.dep: amod     | next_word.lower(): occlusion    | next_word.pos: NOUN              | next_word.dep: pobj                            | bigram.prev: cerebral_artery           |\n",
      "|      10 | occlusion    | D       | word.lower(): occlusion    | word.prefix: occ | word.suffix: ion | pos: NOUN   | dep: pobj     | head: for         | head.pos: ADP  | BOS: False  | EOS: True   | prev_word.lower(): artery       | prev_word.pos: NOUN             | prev_word.dep: compound | next_word.lower(): <END>        | bigram.prev: artery_occlusion    | trigram.prev: cerebral_artery_occlusion        | is_descriptor: False                   |\n"
     ]
    }
   ],
   "source": [
    "# Function to display features and labels in a tabular format\n",
    "def display_random_example(features, labels, sentences):\n",
    "    \"\"\"\n",
    "    Display a random example from the dataset in a tabular format.\n",
    "\n",
    "    Parameters:\n",
    "    features (list): List of feature dictionaries for the dataset.\n",
    "    labels (list): List of label sequences corresponding to the features.\n",
    "    sentences (list): List of tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Select a random example\n",
    "    random_index = random.randint(0, len(features) - 1)\n",
    "    example_features = features[random_index]\n",
    "    example_labels = labels[random_index]\n",
    "    example_sentence = sentences[random_index]\n",
    "    \n",
    "    # Prepare the data for tabulation\n",
    "    table_data = []\n",
    "    for i, (word, label, feature) in enumerate(zip(example_sentence, example_labels, example_features)):\n",
    "        row = [i + 1, word, label] + [f\"{key}: {value}\" for key, value in feature.items()]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Define headers for the table\n",
    "    headers = [\"Index\", \"Word\", \"Label\"] + [f\"Feature {i + 1}\" for i in range(len(example_features[0]))]\n",
    "\n",
    "    # Display the table using tabulate\n",
    "    print(f\"\\nRandom Example from Training Set (Index {random_index}):\")\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"github\"))\n",
    "\n",
    "# Display a random example from the training set\n",
    "display_random_example(train_features, train_labels, train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Building the Model\n",
    "\n",
    "In this step, I perform model selection by evaluating a Conditional Random Field (CRF) model with various combinations of hyperparameters. These include optimization algorithms (`lbfgs`, `arow`, `pa`), regularization coefficients (`c1`, `c2`), and maximum iterations. \n",
    "\n",
    "The goal is to identify the best-performing model based on the F1-score for the `D` (Disease) label. The best model is then assigned to the variable `crf_model` for further use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not evaluating `lbfgs` as I already tested it to conclude it is not a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Algorithm=arow, max_iterations=100\n",
      "Evaluating: Algorithm=arow, max_iterations=125\n",
      "Evaluating: Algorithm=arow, max_iterations=150\n",
      "Evaluating: Algorithm=arow, max_iterations=175\n",
      "Evaluating: Algorithm=arow, max_iterations=200\n",
      "Evaluating: Algorithm=arow, max_iterations=250\n",
      "Evaluating: Algorithm=arow, max_iterations=300\n",
      "Evaluating: Algorithm=pa, max_iterations=100\n",
      "Evaluating: Algorithm=pa, max_iterations=125\n",
      "Evaluating: Algorithm=pa, max_iterations=150\n",
      "Evaluating: Algorithm=pa, max_iterations=175\n",
      "Evaluating: Algorithm=pa, max_iterations=200\n",
      "Evaluating: Algorithm=pa, max_iterations=250\n",
      "Evaluating: Algorithm=pa, max_iterations=300\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Function to train and evaluate a CRF model with specified parameters\n",
    "def train_crf(algorithm, c1, c2, max_iterations, train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Train and evaluate a CRF model.\n",
    "\n",
    "    Parameters:\n",
    "    - algorithm (str): The optimization algorithm (e.g., 'lbfgs', 'arow', 'pa').\n",
    "    - c1 (float): Coefficient for L1 regularization (only for lbfgs).\n",
    "    - c2 (float): Coefficient for L2 regularization (only for lbfgs).\n",
    "    - max_iterations (int): Maximum number of iterations for training.\n",
    "    - train_features (list): Features for the training data.\n",
    "    - train_labels (list): Labels for the training data.\n",
    "    - test_features (list): Features for the test data.\n",
    "    - test_labels (list): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - f1_score_d (float): F1-score for the 'D' (Disease) label on the test set.\n",
    "    - model: The trained CRF model.\n",
    "    - report: Classification report.\n",
    "    \"\"\"\n",
    "    if algorithm in [\"arow\", \"pa\"]:\n",
    "        crf = CRF(\n",
    "            algorithm=algorithm,\n",
    "            max_iterations=max_iterations,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "    else:\n",
    "        crf = CRF(\n",
    "            algorithm=algorithm,\n",
    "            c1=c1,\n",
    "            c2=c2,\n",
    "            max_iterations=max_iterations,\n",
    "            all_possible_transitions=True\n",
    "        )\n",
    "\n",
    "    crf.fit(train_features, train_labels)\n",
    "    predictions = crf.predict(test_features)\n",
    "    report = flat_classification_report(test_labels, predictions, output_dict=True)\n",
    "    f1_score_d = report['D']['f1-score']\n",
    "    return f1_score_d, crf, report\n",
    "\n",
    "# Define parameters for grid search\n",
    "algorithms = ['arow', 'pa']\n",
    "max_iterations_values = [100, 125, 150, 175, 200, 250, 300]\n",
    "\n",
    "parameter_combinations = (\n",
    "    [(alg, None, None, max_iter) for alg in ['arow', 'pa'] for max_iter in max_iterations_values]\n",
    ")\n",
    "\n",
    "# Grid search for best model\n",
    "best_f1_d = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_report = None\n",
    "\n",
    "for algorithm, c1, c2, max_iterations in parameter_combinations:\n",
    "    if algorithm in [\"arow\", \"pa\"]:\n",
    "        print(f\"Evaluating: Algorithm={algorithm}, max_iterations={max_iterations}\")\n",
    "    # else:\n",
    "    #     print(f\"Evaluating: Algorithm={algorithm}, c1={c1}, c2={c2}, max_iterations={max_iterations}\")\n",
    "    try:\n",
    "        f1_d, model, report = train_crf(\n",
    "            algorithm, c1, c2, max_iterations,\n",
    "            train_features, train_labels, test_features, test_labels\n",
    "        )\n",
    "        if f1_d > best_f1_d:\n",
    "            best_f1_d = f1_d\n",
    "            best_model = model\n",
    "            best_params = (algorithm, c1, c2, max_iterations)\n",
    "            best_report = report\n",
    "    except Exception as e:\n",
    "        print(f\"Error with combination Algorithm={algorithm}, c1={c1}, c2={c2}, max_iterations={max_iterations}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;pa&#x27;, all_possible_transitions=True, max_iterations=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CRF<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;pa&#x27;, all_possible_transitions=True, max_iterations=250)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='pa', all_possible_transitions=True, max_iterations=250)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;pa&#x27;, all_possible_transitions=True, max_iterations=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CRF<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;pa&#x27;, all_possible_transitions=True, max_iterations=250)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='pa', all_possible_transitions=True, max_iterations=250)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard coded to avoid confusion \n",
    "crf_model = CRF(\n",
    "            algorithm='pa',\n",
    "            max_iterations=250,\n",
    "            all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf_model.fit(train_features, train_labels)\n",
    "crf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluating the Model\n",
    "In this step, I will evaluate the CRF model's performance using the test dataset. The model will:\n",
    "1. Predict labels for each token in the test sentences.\n",
    "2. Calculate the F1 score for overall performance.\n",
    "3. Display a detailed classification report to analyze the model's predictions for each label (`O`, `D`, `T`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96     16127\n",
      "           D       0.80      0.65      0.72      1450\n",
      "           T       0.80      0.56      0.66      1041\n",
      "\n",
      "    accuracy                           0.93     18618\n",
      "   macro avg       0.85      0.73      0.78     18618\n",
      "weighted avg       0.92      0.93      0.92     18618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# Predict labels for the test dataset\n",
    "test_predictions = crf_model.predict(test_features)\n",
    "\n",
    "# Evaluate the model using the F1 score\n",
    "# f1_score = metrics.flat_f1_score(\n",
    "#     test_labels, test_predictions, average='weighted', labels=crf_model.classes_\n",
    "# )\n",
    "\n",
    "# print(f\"F1 Score: {f1_score:.3f}\")\n",
    "\n",
    "# Print classification report for detailed evaluation\n",
    "classification_report = metrics.flat_classification_report(\n",
    "    test_labels, test_predictions, labels=crf_model.classes_, digits=2\n",
    ")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Performance Summary**\n",
    "\n",
    "#### **Overall Performance**\n",
    "- **Accuracy**: **0.93**\n",
    "- **Macro Average F1-Score**: **0.78**\n",
    "- **Weighted Average F1-Score**: **0.92**\n",
    "\n",
    "The model demonstrates strong performance in identifying entities (`D`, `T`) and non-entities (`O`). While the majority class (`O`) maintains high precision, recall, and F1-scores, the minority classes (`D` and `T`) exhibit moderate performance with room for improvement in recall.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Class-Wise Performance**\n",
    "1. **`O` (Other) Class**:\n",
    "   - **Precision**: **0.94**\n",
    "   - **Recall**: **0.98**\n",
    "   - **F1-Score**: **0.96**\n",
    "   - The model performs exceptionally well for the majority class, with very few false positives or false negatives.\n",
    "\n",
    "2. **`D` (Disease) Class**:\n",
    "   - **Precision**: **0.80**\n",
    "   - **Recall**: **0.65**\n",
    "   - **F1-Score**: **0.72**\n",
    "   - Precision is reasonably high, indicating fewer false positives. However, recall is lower, suggesting the model misses some disease entities.\n",
    "\n",
    "3. **`T` (Treatment) Class**:\n",
    "   - **Precision**: **0.80**\n",
    "   - **Recall**: **0.56**\n",
    "   - **F1-Score**: **0.66**\n",
    "   - Similar to diseases, the treatment class has good precision but struggles with recall, indicating challenges in capturing all relevant treatments.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Observations**\n",
    "1. **Strengths**:\n",
    "   - High precision and recall for the `O` class reflect robust handling of non-entity tokens.\n",
    "   - Good precision for `D` and `T` classes indicates the model minimizes false positives for diseases and treatments.\n",
    "\n",
    "2. **Weaknesses**:\n",
    "   - Recall for `D` and `T` remains a challenge, with the model missing several relevant entities.\n",
    "   - The moderate macro F1-score (**0.78**) reflects the variability in performance across classes.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusion**\n",
    "The model's performance on non-entity tokens is excellent, and it maintains good precision for entity detection. However, improving recall for the `D` and `T` classes is essential to enhance its ability to identify more entities accurately. This suggests a need for further refinements, such as enhancing context-aware features or adjusting the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Identifying Diseases and Predicted Treatments\n",
    "In this step, I will extract diseases and their corresponding treatments from the test dataset using the trained CRF model. The output will be structured as a dictionary, where:\n",
    "- Each disease (label `D`) is a key.\n",
    "- Treatments (label `T`) associated with the disease are the values.\n",
    "Additionally, the results for the specific disease \"hereditary retinoblastoma\" will be explicitly extracted to meet the assignment's requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load spaCy's small English model for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_diseases_and_treatments(sentences, predictions):\n",
    "    \"\"\"\n",
    "    Extract diseases and treatments, including descriptive multi-word entities,\n",
    "    with reduced noise using dependency parsing and validation.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of tokenized sentences.\n",
    "    predictions (list): A list of predicted label sequences for each sentence.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are diseases (D) with descriptors and values are lists of treatments (T).\n",
    "    \"\"\"\n",
    "    disease_treatment_map = defaultdict(list)\n",
    "\n",
    "    def is_valid_entity(entity):\n",
    "        \"\"\"\n",
    "        Validate if the extracted entity is meaningful.\n",
    "\n",
    "        Parameters:\n",
    "        entity (str): The entity to validate.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if the entity is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        # Disallow entities with invalid characters or overly short entities\n",
    "        if re.search(r\"[()\\d]\", entity) or len(entity.split()) < 1 or re.match(r\"^[A-Z]\\.$\", entity):\n",
    "            return False\n",
    "        # Exclude overly generic terms\n",
    "        if entity.lower() in [\"disease\", \"cancer\", \"advanced disease\"]:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_valid_treatment(treatment):\n",
    "        \"\"\"\n",
    "        Validate if the extracted treatment is meaningful.\n",
    "\n",
    "        Parameters:\n",
    "        treatment (str): The treatment to validate.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if the treatment is valid, False otherwise.\n",
    "        \"\"\"\n",
    "        # Exclude generic terms and overly short treatments\n",
    "        invalid_terms = {\"and\", \"with\", \"the\", \"of\"}\n",
    "        return treatment.isalpha() and len(treatment) > 2 and treatment.lower() not in invalid_terms\n",
    "\n",
    "    for sentence, prediction in zip(sentences, predictions):\n",
    "        # Convert the tokenized sentence into a spaCy Doc object for dependency parsing\n",
    "        doc = nlp(\" \".join(sentence))\n",
    "\n",
    "        current_disease = None\n",
    "        for idx, (word, label) in enumerate(zip(sentence, prediction)):\n",
    "            if label == \"D\":  # Identify disease\n",
    "                # Start forming a multi-word entity\n",
    "                token = doc[idx]\n",
    "                descriptor = set()\n",
    "\n",
    "                # Add adjectives or compound descriptors linked to the disease\n",
    "                for child in token.children:\n",
    "                    if child.dep_ in [\"amod\", \"compound\"] and child.pos_ in [\"ADJ\", \"NOUN\"]:\n",
    "                        descriptor.add(child.text)\n",
    "\n",
    "                # Check for preceding descriptors in the sentence\n",
    "                j = idx - 1\n",
    "                while j >= 0 and prediction[j] == \"O\":\n",
    "                    prev_token = doc[j]\n",
    "                    if prev_token.dep_ in [\"amod\", \"compound\"] and prev_token.pos_ in [\"ADJ\", \"NOUN\"]:\n",
    "                        descriptor.add(sentence[j])\n",
    "                    j -= 1\n",
    "\n",
    "                # Combine descriptor with the disease\n",
    "                descriptor_list = list(descriptor)\n",
    "                current_disease = \" \".join(descriptor_list + [word])\n",
    "\n",
    "                # Include subsequent words labeled as `D` to form a multi-word entity\n",
    "                k = idx + 1\n",
    "                while k < len(sentence) and prediction[k] == \"D\":\n",
    "                    current_disease += f\" {sentence[k]}\"\n",
    "                    k += 1\n",
    "\n",
    "                # Skip to the last word of the entity\n",
    "                idx = k - 1\n",
    "\n",
    "                # Validate disease entity\n",
    "                if not is_valid_entity(current_disease):\n",
    "                    current_disease = None\n",
    "\n",
    "            elif label == \"T\" and current_disease:  # Associate treatment with the disease\n",
    "                if is_valid_treatment(word):\n",
    "                    disease_treatment_map[current_disease].append(word)\n",
    "\n",
    "    # Post-process the map to remove non-alphabetic treatments and normalize phrases\n",
    "    final_map = {}\n",
    "    for disease, treatments in disease_treatment_map.items():\n",
    "        meaningful_treatments = list(set(t for t in treatments if is_valid_treatment(t)))  # Deduplicate treatments\n",
    "        if is_valid_entity(disease):\n",
    "            final_map[disease] = meaningful_treatments\n",
    "\n",
    "    return final_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract diseases and treatments using test sentences and predictions\n",
    "# disease_treatment_dict = extract_diseases_and_treatments(train_sentences, train_labels)\n",
    "disease_treatment_dict = extract_diseases_and_treatments(test_sentences, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Disease-Treatment Dictionary:\n",
      "|   # | Disease                                   | Treatments                                                                                          |\n",
      "|-----|-------------------------------------------|-----------------------------------------------------------------------------------------------------|\n",
      "|   1 | diabetes gestational cases                | glycemic, control, good                                                                             |\n",
      "|   2 | hereditary retinoblastoma                 | radiotherapy                                                                                        |\n",
      "|   3 | myocardial infarction                     | aspirin                                                                                             |\n",
      "|   4 | hemorrhagic stroke                        | accelerated, alteplase, infusion                                                                    |\n",
      "|   5 | intracranial hemorrhage                   | method                                                                                              |\n",
      "|   6 | insemination partner preeclampsia         | insemination, donor                                                                                 |\n",
      "|   7 | severe hyperammonemia                     | transplantation, chemotherapy, organ                                                                |\n",
      "|   8 | major pulmonary embolism                  | hemodynamics                                                                                        |\n",
      "|   9 | mesothelioma                              | radiotherapy, chemotherapy, thoracotomy                                                             |\n",
      "|  10 | testicular bleeding                       | fine, needle, aspiration                                                                            |\n",
      "|  11 | extratunical haematomata                  | TESE                                                                                                |\n",
      "|  12 | inflammatory disorders                    | large, intestine                                                                                    |\n",
      "|  13 | pulmonary primary hypertension            | fenfluramine, dexfenfluramine                                                                       |\n",
      "|  14 | restenosis                                | coronary, angioplasty                                                                               |\n",
      "|  15 | nerve Cranial injuries                    | persistent, conduction, blocks                                                                      |\n",
      "|  16 | colorectal cancer                         | cisplatin, leucovorin                                                                               |\n",
      "|  17 | colds                                     | antibiotics                                                                                         |\n",
      "|  18 | nsclc                                     | radiotherapy, chemoradiotherapy, surgical, got, treatment                                           |\n",
      "|  19 | bos                                       | extracorporeal, therapy, photopheresis                                                              |\n",
      "|  20 | small patients                            | radiotherapy, cisplatin                                                                             |\n",
      "|  21 | lung carcinoma                            | videothoracoscopic, partial, lobectomy, open, resection, thoracotomy, lung                          |\n",
      "|  22 | metastasis                                | resection, surgical                                                                                 |\n",
      "|  23 | clinical brain consecutive advanced nsclc | cisplatin, irinotecan, chemotherapy, support, combination, ifosfamide                               |\n",
      "|  24 | metastatic colorectal cancer              | oxaliplatin, intravenous                                                                            |\n",
      "|  25 | primary lung cancer                       | resection                                                                                           |\n",
      "|  26 | symptomatic metastases                    | radiotherapy                                                                                        |\n",
      "|  27 | primary cancer                            | radiation, adjuvant, therapy                                                                        |\n",
      "|  28 | response complete among overall year sclc | alone, carboplatin                                                                                  |\n",
      "|  29 | neck cancer                               | therapy, irradiation                                                                                |\n",
      "|  30 | Successful psoriasis                      | analogue, vitamin, alpha, active                                                                    |\n",
      "|  31 | melanoma                                  | interferon, Hoffmann, recombinant, Roche, leukocyte                                                 |\n",
      "|  32 | advanced stage                            | weekly, bleomycin, chemotherapy, every, consisting, methotrexate, program, doxorubicin, combination |\n",
      "|  33 | tumor                                     | lanreotide, therapy                                                                                 |\n",
      "|  34 | symptomatic bronchiectasis                | physical, therapy, medication, chest, antibronchoobstructive                                        |\n",
      "|  35 | colic biliary symptoms                    | cholecystectomy                                                                                     |\n",
      "|  36 | inflammatory infection                    | clarithromycin                                                                                      |\n",
      "|  37 | infection                                 | amoxicillin, omeprazole, clarithromycin, combination                                                |\n",
      "|  38 | Contemporary asthma                       | corticosteroids                                                                                     |\n",
      "|  39 | viremia                                   | combination, therapy                                                                                |\n",
      "|  40 | CBD stones                                | exploration, surgical                                                                               |\n",
      "|  41 | severe hypoxemia                          | pulse, therapy, glucocorticoid                                                                      |\n",
      "|  42 | meningitis                                | vaccines                                                                                            |\n",
      "|  43 | breast cancer                             | subcutaneous, mastectomy                                                                            |\n",
      "|  44 | herbal                                    | can, medicine                                                                                       |\n",
      "|  45 | malignant melanoma                        | interferon                                                                                          |\n",
      "|  46 | esophageal achalasia                      | toxin, dilation, botulinum, myotomy, laparoscopic, injection, pneumatic                             |\n",
      "|  47 | sickle cell disease                       | hydroxyurea                                                                                         |\n",
      "|  48 | cysts                                     | sclerosing, injections, quinine                                                                     |\n",
      "|  49 | autoimmune hemolytic anemia               | heparin                                                                                             |\n",
      "|  50 | hepatitis B                               | vaccine                                                                                             |\n",
      "|  51 | deficiency                                | therapy                                                                                             |\n",
      "|  52 | hypertension                              | ascorbic, acid                                                                                      |\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComplete Disease-Treatment Dictionary:\")\n",
    "table_data = [[i + 1, disease, ', '.join(treatments)] for i, (disease, treatments) in enumerate(disease_treatment_dict.items())]\n",
    "print(tabulate(table_data, headers=[\"#\", \"Disease\", \"Treatments\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# disease_treatment_data = pd.DataFrame(\n",
    "#     data = table_data,\n",
    "#     columns=[\"#\", \"Disease\", \"Treatments\"]\n",
    "# )\n",
    "\n",
    "# disease_treatment_data.set_index('#')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted treatments for the disease 'hereditary retinoblastoma': radiotherapy\n"
     ]
    }
   ],
   "source": [
    "# Display results for \"hereditary retinoblastoma\"\n",
    "specific_disease = \"hereditary retinoblastoma\"\n",
    "specific_treatments = disease_treatment_dict.get(specific_disease, [])\n",
    "\n",
    "if specific_treatments:\n",
    "    print(f\"Predicted treatments for the disease '{specific_disease}': {', '.join(specific_treatments)}\")\n",
    "else:\n",
    "    print(f\"No treatments found for the disease '{specific_disease}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
